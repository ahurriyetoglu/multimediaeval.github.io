<!DOCTYPE html>

<html lang="en">
  <head>
  <meta charset="UTF-8">
  <link rel="shortcut icon" href="/assets/img/mediaeval-favicon.png" type="image/png">
  <!--Import Google Icon Font-->
  <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
  <!--Import materialize.css-->
  <link type="text/css" rel="stylesheet" href="/assets/css/materialize.min.css"  media="screen,projection"/>
  <link type="text/css" rel="stylesheet" href="/assets/css/main.css"  media="screen,projection"/>
  <!-- Add icon library -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <!--Let browser know website is optimized for mobile-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <meta name="twitter:card" content="summary" /> <!--<meta name="twitter:card" content="summary_large_image" />-->
  <meta name="twitter:image" content="https://multimediaeval.github.io/assets/img/twitter-card-summary.png"/>
  <meta name="twitter:image:alt" content="Picture of group of people participants of the 2019 MediaEval workshop"/>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  

  <!-- seo tags -->
  <!-- Begin Jekyll SEO tag v2.6.1 -->
<title>In-Car Driver Video Privacy | MediaEval Benchmark</title>
<meta name="generator" content="Jekyll v3.9.0" />
<meta property="og:title" content="In-Car Driver Video Privacy" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="See the MediaEval 2021 webpage for information on how to register and participate." />
<meta property="og:description" content="See the MediaEval 2021 webpage for information on how to register and participate." />
<link rel="canonical" href="https://multimediaeval.github.io/editions/2021/tasks/videoprivacy/" />
<meta property="og:url" content="https://multimediaeval.github.io/editions/2021/tasks/videoprivacy/" />
<meta property="og:site_name" content="MediaEval Benchmark" />
<meta property="og:image" content="https://multimediaeval.github.io/assets/img/twitter-card.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-06-04T08:27:35+00:00" />
<script type="application/ld+json">
{"@type":"BlogPosting","image":"https://multimediaeval.github.io/assets/img/twitter-card.png","mainEntityOfPage":{"@type":"WebPage","@id":"https://multimediaeval.github.io/editions/2021/tasks/videoprivacy/"},"headline":"In-Car Driver Video Privacy","dateModified":"2021-06-04T08:27:35+00:00","datePublished":"2021-06-04T08:27:35+00:00","url":"https://multimediaeval.github.io/editions/2021/tasks/videoprivacy/","description":"See the MediaEval 2021 webpage for information on how to register and participate.","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

  <!-- Manual seo tags -->

</head>

  <body>

    <div>
    


<div class="navbar-fixed">
  <nav>
    <div class="nav-wrapper green darken-4">
      <a href="/" class="brand-logo" style="padding-left: 20px">
        <h3 class="northumbria" style="margin-top: 20px;color:white;">Mediaeval</h3>
      </a>
      <!-- Small screen definition -->
      <a href="#" data-target="mobile-nav" class="sidenav-trigger">
        <i class="material-icons" style="color:white;">menu</i>
      </a>
      <!-- Big screen Structure -->
      <ul class="materialize right hide-on-med-and-down">
        <li><a href="/"><i class="material-icons" style="color:white;">home</i></a></li>
        
          <li><a href="/editions/2021/" style="color:white;">MediaEval 2021</a></li>
        
        
          
            
              <li><a class="dropdown-trigger" data-target="editions" style="color:white;">
                MediaEval History<i class="material-icons right">arrow_drop_down</i>
              </a></li>
            
          
        
          
            
              <li><a href="/about/" style="color:white;">About MediaEval</a></li>
            
          
        
          
            
              <li><a href="/bib/" style="color:white;">Bibliography</a></li>
            
          
        
          
        
          
        
          
        
          
        
      </ul>
    </div>
  </nav>
</div>

<!-- Big screen dropdown Structure -->
<ul class="dropdown-content materialize" id="editions">
  
  <li><a href="/editions/2020/">MediaEval 2020</a></li>
  
  <li><a href="http://www.multimediaeval.org/" target="_blank">pre-2020</a></li>
</ul>

<!-- Mobile Structure -->
<ul class="materialize sidenav green darken-4" id="mobile-nav">
  <li><a href="/" style="color:white;">Home</a></li>
  
  <li><a href="/editions/2021/" style="color:white;">MediaEval 2021</a></li>
  
  
    
      
  <li><a class="dropdown-trigger" data-target="mobile-editions" style="color:white;">
    MediaEval History<i class="material-icons right" style="color:white;">arrow_drop_down</i>
  </a></li>
      
    
  
    
      
  <li><a href="/about/" style="color:white;">About MediaEval</a></li>
      
    
  
    
      
  <li><a href="/bib/" style="color:white;">Bibliography</a></li>
      
    
  
    
  
    
  
    
  
    
  
</ul>

<!-- Mobile dropdown Structure -->
<ul class="dropdown-content materialize" id="mobile-editions">
  
  <li><a href="/editions/2020/">MediaEval 2020</a></li>
  
  <li><a href="http://www.multimediaeval.org/" target="_blank">pre-2020</a></li>
</ul>

</div>

    

    <div class="container">
      <div class="row">
          <header id="main" style="background-image: url('')">
    <h2>In-Car Driver Video Privacy</h2>
  </header>

  <!-- # please respect the structure below-->
<p><em>See the <a href="https://multimediaeval.github.io/editions/2021/">MediaEval 2021 webpage</a> for information on how to register and participate.</em></p>

<h4 id="task-description">Task Description</h4>
<p>The goal of this video data task is to explore methods for obscuring driver identity in driver-facing video recordings while preserving human behavioral information.</p>

<p>Participants are required to develop obfuscation methods, and to submit an obfuscated data set.</p>

<p>The obfuscated data must simultaneously fulfill two criteria:</p>
<ul>
  <li>Driver identity must be obscured.</li>
  <li>The video must still be useful for classifying a set of driver behaviors including include talking, coughing, singing, dancing, waving, eating.</li>
</ul>

<p>(1) The drivers are not known to the potential attacker. We assume there is no relationship between the attacker and the driver. Furthermore, it is assumed that the driver is not a public figure. (2) Any information from the driver’s surroundings is assumed to not influence the attacker’s ability to identify the driver. (3) Access to the data is limited to registered users who have signed a Data Use Agreement specifying they will not attempt to learn the identity of individuals in the videos. (4) Attackers have access to basic computational resources. (5) There is low probability of attackers launching an effective crowdsourcing strategy to re-identify the drivers, in part due to the Data Use Agreement and context in which the data were collected.</p>

<p>Although we encourage all Task participants to think creatively and holistically about how the expectations of privacy, the risk from potential attackers, and various threat models may evolve, our starting assumptions are that:</p>

<p>The organizers of this Task encourage open source code with a MIT license, and the open sharing of insights to support a multidisciplinary community of practice. We anticipate that with the engagement of the MediaEval community there will be multiple opportunities to highlight both quantitative and qualitative feedback from participants, supporting reproducibility, open science, and future collaborative research.</p>

<h4 id="motivation-and-background">Motivation and background</h4>
<p>The lifetime odds for dying in a car crash are high. In the United States, they have been reported to be 1 in 107 [1] and to cost hundreds of billions of dollars [2]. Research shows that driver behavior is a primary factor in ⅔ of crashes and a contributing factor in 90% of crashes [3]. In order to prevent crashes, it is essential to have better understanding of driver behavior.</p>

<p>A unique opportunity to study driver behavior is presented by video footage from driver-facing cameras. This opportunity is being pursued by the Second Strategic Highway Research Program (SHRP2) worked with drivers across the country to collect more than 1 million hours of driver video [4, 5].</p>

<p>However, video data analysis and interpretation related to identifiable human subjects bring forward a variety of multifaceted questions and concerns, spanning privacy, security, bias, and additional implications [6]. This task aims to advance the state-of-the-art in video de-identification, encouraging participants to develop and demonstrate techniques with the provided data. Successful methods balancing driver privacy with fidelity of relevant information have the potential to not only broaden researcher access to existing data, but also inform the trajectory of transportation safety research, policy, and education initiatives [7].</p>

<p>This task, as a collaboration between the National Science Foundation, U.S. Department of Transportation, and a network of institutions, is centered on societal impact. The effort represents a key opportunity for reproducible and responsible multidisciplinary research, connecting a broad community of stakeholders to contribute to public safety and critical dialogue at the intersection of data science, privacy, ethics, and data protection.</p>

<h4 id="target-group">Target group</h4>
<p>Participants of all experience levels and backgrounds with interests including de-identification techniques, video analytics, transportation safety, security, privacy, human behavior, and risk assessment are invited to engage in and contribute to this task. From expert researchers in academia and industry to students, nonprofit organizations, and government, all are encouraged to explore the data and submit approaches and technical demonstrations of driver de-identification.</p>

<h4 id="data">Data</h4>
<p>The data set consists of both high- and low-resolution driver video data prepared by Oak Ridge National Laboratory for this Driver Video Privacy Challenge. The data were captured using the same data acquisition system as the larger SHRP2 dataset mentioned above, which currently is in a secure enclave with limited acess.</p>

<p>The data set contains are 10 distinct drivers in choreographed situations designed to emulate different naturalistic driving environments. Actions include talking, coughing, singing, dancing, waving, eating, and various others [8].</p>

<p>Through this unique partnership, annotated data from Oak Ridge National Laboratory will be available to any interested participants, alongside experts from the data collection and processing team who will be available for mentoring and any questions.</p>

<h4 id="evaluation-methodology">Evaluation methodology</h4>
<p>The evaluation process includes an automated evaluation as well as a human evaluation, to assess the de-identification of faces and measure the consistency in preserving driver actions and emotions.</p>

<p>An initial automated process will be run using a deep learning-based gaze estimator. The difference in predicted gaze-vectors from the original un-filtered video and de-identified video will be used as an initial score.  Human evaluators will use the evaluation methodology as described by Baragchizadeh et al. in Evaluation of Automated Identity Masking Method (AIM) in Naturalistic Driving Study (NDS) [9].</p>

<p>The scores for each of these areas will be combined for an overall assessment and the participants’ descriptions of methodology, assumptions, and results will be shared for additional discussion and opportunities for seed funding further research.</p>

<h4 id="references-and-recommended-reading">References and recommended reading</h4>
<!-- # Please use the ACM format for references https://www.acm.org/publications/authors/reference-formatting (but no DOI needed)-->
<!-- # The paper title should be a hyperlink leading to the paper online-->

<p>[1] Odds of dying. (2021, March 04). Retrieved March 28, 2021, from    https://injuryfacts.nsc.org/all-injuries/preventable-death-overview/odds-of-dying/</p>

<p>[2] Blincoe, L. J., Miller, T. R., Zaloshnja, E., &amp; Lawrence, B. A. (2015, May). The economic and societal impact of motor vehicle crashes, 2010. (Revised)(Report No. DOT HS 812 013). Washington, DC: National Highway Traffic Safety Administration.</p>

<p>[3] Dingus, T., Guo, F., Lee, S., Antin, J., Perez, M., Buchanan-King, M., &amp; Hankey, J. (2016,  March 08). Driver crash risk factors and prevalence evaluation using naturalistic driving data. Retrieved April 18, 2021, from https://www.pnas.org/content/113/10/2636</p>

<p>[4] About safety Data: Strategic Highway research Program 2 (SHRP 2). (n.d.). Retrieved from                      http://www.trb.org/StrategicHighwayResearchProgram2SHRP2/SHRP2DataSafetyAbout.aspx</p>

<p>[5] A Brief Look at the History of SHRP2     http://shrp2.transportation.org/pages/History-of-SHRP2.aspx</p>

<p>[6] Finch, K. (2016, April 25). A visual guide to practical data de-identification. Retrieved March 28, 2021, from https://fpf.org/blog/a-visual-guide-to-practical-data-de-identification/</p>

<p>[7] Exploratory Advanced Research Program Video Analytics Research Projects https://www.fhwa.dot.gov/publications/research/ear/15025/15025.pdf</p>

<p>[8] Ferrell, R., Aykac, D., Karnowski, T., &amp; Srinivas, N. (2021, January). A Publicly Available, Annotated Data Set for Naturalistic Driving Study and Computer Vision Algorithm Development. Retrieved from https://info.ornl.gov/sites/publications/Files/Pub122418.pdf</p>

<p>[9] Baragchizadeh, Asal, O’Toole, Alice, Karnowski, Thomas Paul, &amp; Bolme, David S. Evaluation of Automated Identity Masking Method (AIM) in Naturalistic Driving Study (NDS). United States. https://doi.org/10.1109/FG.2017.54</p>

<h4 id="task-organizers">Task organizers</h4>
<p>Please get in touch. Experts from the data collection and processing team are available for mentoring and any questions.</p>

<ul>
  <li>Meredith Lee, University of California, Berkeley, USA mmlee (at) berkeley.edu</li>
  <li>Gerald Friedland, University of California, Berkeley, USA  fractor (at) berkeley.edu</li>
  <li>Alex Liu, University of California, Berkeley, USA</li>
  <li>Andrew Boka, University of California, Berkeley, USA</li>
  <li>Arjun Sarup, University of California, Berkeley, USA</li>
</ul>

<h4 id="task-auxiliaries">Task auxiliaries</h4>
<!-- # optional, delete if not used-->
<ul>
  <li>
    <!-- # First auxiliary-->
  </li>
  <li>
    <!-- # Second auxiliary-->
    <!-- # and so on-->
  </li>
</ul>

<h4 id="task-schedule">Task Schedule</h4>
<ul>
  <li>XX XXX: Data release <!-- # Replace XX with your date. We suggest setting the date in June-July--></li>
  <li>XX November: Runs due <!-- # Replace XX with your date. We suggest setting enough time in order to have enough time to assess and return the results by the Results returned deadline--></li>
  <li>XX November: Results returned  <!-- Replace XX with your date. Latest possible should be 15 November--></li>
  <li>22 November: Working notes paper  <!-- Fixed. Please do not change. Exact date to be decided--></li>
  <li>Beginning December: MediaEval 2020 Workshop <!-- Fixed. Please do not change. Exact date to be decided--></li>
</ul>

<h4 id="acknolwedgments">Acknolwedgments</h4>
<!-- # optional, delete if not used-->


      </div>
    </div>

    
<footer class='page-footer green darken-4'>
  <div class='container'>

    <div class='row'>
      <div class="col l6 s12">
        <h5 class="white-text">What is MediaEval?</h5>
        <p>MediaEval is a benchmarking initiative dedicated to evaluating new algorithms for multimedia access and retrieval. 
          It emphasizes the ‘multi’ in multimedia and focuses on human and social aspects of multimedia tasks.</p>

        <p>For more information contact Martha Larson m.larson (at) cs.ru.nl</p>
      </div>
      <div class="col l4 offset-l2 s12">
        <h5 class="white-text">Links</h5>
        <a href='https://twitter.com/multimediaeval' target="_blank">
          <i class="fa fa-twitter fa-3x" aria-hidden="true" style="color:white;"></i>
        </a>
        <a href='https://github.com/multimediaeval' target="_blank">
          <i class="fa fa-github fa-3x" aria-hidden="true" style="color:white;"></i>
        </a>
        <a href='https://www.flickr.com/photos/69524595@N06/' target="_blank">
          <i class="fa fa-flickr fa-3x" aria-hidden="true" style="color:white;"></i>
        </a>
        <a href='https://www.youtube.com/channel/UCc-1NW1Uo2o_zI4F81iyTcw' target="_blank">
          <i class="fa fa-youtube fa-3x" aria-hidden="true" style="color:white;"></i>
        </a>
      </div>
    </div>

  </div>
    <div class="footer-copyright">
      <div class="container grey-text text-lighten-4">
      &copy; 2020 MediaEval Multimedia Benchmark
    </div>
  </div>
</footer>


    <!--JavaScript at end of body for optimized loading-->
    <script type="text/javascript" src="/assets/js/materialize.min.js"></script>
    <script type="text/javascript" src="/assets/js/main.js"></script>
  </body>

</html>
