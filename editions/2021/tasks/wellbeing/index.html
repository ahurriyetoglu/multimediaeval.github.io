<!DOCTYPE html>

<html lang="en">
  <head>
  <meta charset="UTF-8">
  <link rel="shortcut icon" href="/assets/img/mediaeval-favicon.png" type="image/png">
  <!--Import Google Icon Font-->
  <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
  <!--Import materialize.css-->
  <link type="text/css" rel="stylesheet" href="/assets/css/materialize.min.css"  media="screen,projection"/>
  <link type="text/css" rel="stylesheet" href="/assets/css/main.css"  media="screen,projection"/>
  <!-- Add icon library -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <!--Let browser know website is optimized for mobile-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <meta name="twitter:card" content="summary" /> <!--<meta name="twitter:card" content="summary_large_image" />-->
  <meta name="twitter:image" content="https://multimediaeval.github.io/assets/img/twitter-card-summary.png"/>
  <meta name="twitter:image:alt" content="Picture of group of people participants of the 2019 MediaEval workshop"/>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  

  <!-- seo tags -->
  <!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Insight for Wellbeing: Multimodal personal health lifelog data analysis | MediaEval Benchmark</title>
<meta name="generator" content="Jekyll v3.9.0" />
<meta property="og:title" content="Insight for Wellbeing: Multimodal personal health lifelog data analysis" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="See the MediaEval 2021 webpage for information on how to register and participate." />
<meta property="og:description" content="See the MediaEval 2021 webpage for information on how to register and participate." />
<link rel="canonical" href="https://multimediaeval.github.io/editions/2021/tasks/wellbeing/" />
<meta property="og:url" content="https://multimediaeval.github.io/editions/2021/tasks/wellbeing/" />
<meta property="og:site_name" content="MediaEval Benchmark" />
<meta property="og:image" content="https://multimediaeval.github.io/assets/img/twitter-card.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-06-02T13:27:42+00:00" />
<script type="application/ld+json">
{"@type":"BlogPosting","image":"https://multimediaeval.github.io/assets/img/twitter-card.png","mainEntityOfPage":{"@type":"WebPage","@id":"https://multimediaeval.github.io/editions/2021/tasks/wellbeing/"},"headline":"Insight for Wellbeing: Multimodal personal health lifelog data analysis","dateModified":"2021-06-02T13:27:42+00:00","datePublished":"2021-06-02T13:27:42+00:00","url":"https://multimediaeval.github.io/editions/2021/tasks/wellbeing/","description":"See the MediaEval 2021 webpage for information on how to register and participate.","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

  <!-- Manual seo tags -->

</head>

  <body>

    <div>
    


<div class="navbar-fixed">
  <nav>
    <div class="nav-wrapper green darken-4">
      <a href="/" class="brand-logo" style="padding-left: 20px">
        <h3 class="northumbria" style="margin-top: 20px;color:white;">Mediaeval</h3>
      </a>
      <!-- Small screen definition -->
      <a href="#" data-target="mobile-nav" class="sidenav-trigger">
        <i class="material-icons" style="color:white;">menu</i>
      </a>
      <!-- Big screen Structure -->
      <ul class="materialize right hide-on-med-and-down">
        <li><a href="/"><i class="material-icons" style="color:white;">home</i></a></li>
        
          <li><a href="/editions/2021/" style="color:white;">MediaEval 2021</a></li>
        
        
          
            
              <li><a class="dropdown-trigger" data-target="editions" style="color:white;">
                MediaEval History<i class="material-icons right">arrow_drop_down</i>
              </a></li>
            
          
        
          
            
              <li><a href="/about/" style="color:white;">About MediaEval</a></li>
            
          
        
          
            
              <li><a href="/bib/" style="color:white;">Bibliography</a></li>
            
          
        
          
        
          
        
          
        
          
        
      </ul>
    </div>
  </nav>
</div>

<!-- Big screen dropdown Structure -->
<ul class="dropdown-content materialize" id="editions">
  
  <li><a href="/editions/2020/">MediaEval 2020</a></li>
  
  <li><a href="http://www.multimediaeval.org/" target="_blank">pre-2020</a></li>
</ul>

<!-- Mobile Structure -->
<ul class="materialize sidenav green darken-4" id="mobile-nav">
  <li><a href="/" style="color:white;">Home</a></li>
  
  <li><a href="/editions/2021/" style="color:white;">MediaEval 2021</a></li>
  
  
    
      
  <li><a class="dropdown-trigger" data-target="mobile-editions" style="color:white;">
    MediaEval History<i class="material-icons right" style="color:white;">arrow_drop_down</i>
  </a></li>
      
    
  
    
      
  <li><a href="/about/" style="color:white;">About MediaEval</a></li>
      
    
  
    
      
  <li><a href="/bib/" style="color:white;">Bibliography</a></li>
      
    
  
    
  
    
  
    
  
    
  
</ul>

<!-- Mobile dropdown Structure -->
<ul class="dropdown-content materialize" id="mobile-editions">
  
  <li><a href="/editions/2020/">MediaEval 2020</a></li>
  
  <li><a href="http://www.multimediaeval.org/" target="_blank">pre-2020</a></li>
</ul>

</div>

    

    <div class="container">
      <div class="row">
          <header id="main" style="background-image: url('')">
    <h2>Insight for Wellbeing: Multimodal personal health lifelog data analysis</h2>
  </header>

  <!-- # please respect the structure below-->
<p><em>See the <a href="https://multimediaeval.github.io/editions/2021/">MediaEval 2021 webpage</a> for information on how to register and participate.</em></p>

<h4 id="task-description">Task Description</h4>
<p>This task asks participants to create systems that derive insights from multimodal lifelog data that is important for health and wellbeing. The data set includes weather and air pollution data, lifelog images, and tags all collected from a group of people during a datathon. The datathon participants wear sensors, use smartphones and walk along predefined routes inside a city. Task participants who tackle the “Segment Replacement” subtask first develop a hypothesis about the associations within the data and then build a system that is able to correctly replace segments of data that have been removed. Task participants who tackle the “Personal Air Quality Prediction’’ subtask requires participants to predict AQI (Air Quality Index) using either the underspecified data or full data from a subset of data sources. The data are collected from the “datathon” campaign that took place in Tokyo city, Japan (2019-2020), Chiba city, Japan (2020), Dalat city, Vietnam (2020), and HCM city, Vietnam (2020).</p>

<p>Participants in this task tackle three challenging subtasks:</p>

<p><em>Subtask 1: Segment Replacement:</em> Task participants develop a hypothesis about the associations within the heterogeneous data and build a system that is able to correctly replace segments of data that have been removed.</p>

<p><em>Subtask 2: Personal Air Quality:</em> Task participants develop approaches to automatically predict personal AQI (Air Quality Index) at specific positions and time durations using either the underspecified data or the full data from a subset of data sources. The aim of Personal AQI is to measure the wellbeing of individual people with respect to the quality of the air that they are breathing.</p>

<p><em>Subtask 3: Transfer Learning:</em> Task participants first develop a model on the given dataset, and then transform that model to work on another dataset (probably having different time and date). This task uses dataset from subtask 1 and 2.</p>

<h4 id="motivation-and-background">Motivation and background</h4>
<p>The association between people’s wellbeing and properties of the surrounding environment is an important area of investigation. Although these investigations have a long and rich history, they have focused on the general population. There is a surprising lack of research that investigates the impact of the environment at the scale of individual people. At personal scale, local information about air pollution (e.g. PM2.5, NO2, O3), weather (e.g. temperature, humidity), urban nature (e.g. greenness, liveliness, quietness), and personal behavior (e.g. psychophysiological data) play an important role. It is not always possible to gather plentiful amounts of such data. As the result, a key research question remains open: Can sparse or incomplete data can be used to gain insight into wellbeing? In other words, is there a hypothesis about the associations within the data so that wellbeing can be understood by using a limited amount data? Developing hypotheses about the associations within the heterogeneous data contributes towards building good multimodal models that make it possible to understand the impact of environment on wellbeing at the local and individual scale. Such models are necessary since not all cities are fully covered by standard air pollution and weather stations, and not all people experience the same reaction to the same environment situation. Moreover, images captured by the first-person view could give important cues to help understand that environmental situation in cases in which precise data from air pollution stations is lacking.</p>

<h4 id="target-group">Target group</h4>
<p>This task targets (but is not limited to) researchers in the areas of multimedia information retrieval, machine learning, AI, data science, event-based processing and analysis, multimodal multimedia content analysis, lifelog data analysis, urban computing, environmental science, and atmospheric science.</p>

<h4 id="data">Data</h4>
<p>The Insight for Wellbeing task introduces a novel dataset, namely SEPHLA created by the data collection campaign, namely DATATHON organized in Fukuoka City, Japan (datathon.jp) in 2018 and 2019. The SEPHLA is dataset at the individual scale contained walking routes (e.g. street names, GPS, time), psychophysiological (e.g. footsteps, heart rate), pollutant concentrations (e.g. PM2.5, NO2, O3), weather variables (e.g. temperature, humidity), first-person view images, urban perception tags (e.g. lively, greenness), and emotional tags (e.g. excited, depressed) data collected via wearable sensors, lifelog-cameras, and smart-phones attached to each data collector. The data come with a series of csv and jpg files indexed with the IDs of data collectors. All individual information, especially in images, is blurred for privacy purposes. The copyright of SEPHLA belongs to the National Institute of Information and Communications Technology, Japan (NICT) and will be released for participants only for research purposes.</p>

<h4 id="ground-truth">Ground truth</h4>
<p>The ground truth for the dataset of the two subtasks is collected as follows:</p>
<ul>
  <li>For the Segment Replacement subtask: The correlation among data types collected along a route during a special time duration is manually calculated. All data segments with high correlation are extracted and labeled. Some of data types in these segments will be hidden and the rest is released for participants. For images data, concepts, categories, and scene are automatically detected using Google Visual API.</li>
  <li>For the Personal Air Quality subtask: A set of specific time segments along the routes is labelled with information based on global AQI provided by Fukuoka City plus local AQI calculated by individual sensing data, as well as with tags contributed by the datathon participants that reflect their perceptions of the urban environment and experienced emotions. Images are also semi-automatically annotated with labels relating to the impact of air pollution and weather on vision such as cloudy, fog, windy, and sunny.</li>
</ul>

<h4 id="evaluation-methodology">Evaluation methodology</h4>
<p>For each subtask, the evaluation method is applied as follows:</p>
<ul>
  <li>For the “segment replacement”: We use the Kendall rank correlation coefficient to evaluate the similarity between the participant’s arrangement and the ground truth.</li>
  <li>For the “AQI prediction”: For assessing performance, the classic metric F1 will be deployed.</li>
</ul>

<h4 id="references-and-recommended-reading">References and recommended reading</h4>
<!-- # Please use the ACM format for references https://www.acm.org/publications/authors/reference-formatting (but no DOI needed)-->
<!-- # The paper title should be a hyperlink leading to the paper online-->

<p>[1] Sato, T., Dao, M.S., Kuribayashi, K., and Zettsu, K.: SEPHLA: Challenges and Opportunities within Environment – Personal Health Archives, MMM 2018.</p>

<p>[2] Zhao, P. and Zettsu, K.: Convolution Recurrent Neural Networks for Short-Term Prediction of Atmospheric Sensing Data, The 4th IEEE International Conference on Smart Data (SmartData 2018), pp.815-821</p>

<p>[3] Dao, M. S. and Zettsu, K.: Complex Event Analysis of Urban Environmental Data based on Deep CNN of Spatiotemporal Raster Images, 2018 IEEE International Conference on Big Data (BigData 2018).</p>

<p>[4] datathon.jp</p>

<p>[5] Song, H.J. et al.: Association between Urban Greenness and Depressive Symptoms: Evaluation of Greenness Using Various Indicators, Int. Journals of Environmental Research and Public Health, 16(173).</p>

<p>[6] D. Santani, S. Ruiz-Correa, and D. Gatica-Perez: Looking South: Learning Urban Perception in Developing Cities, ACM Transactions on Social Computing, 1(3), Article 13, Dec. 2018</p>

<p>[7] Dang-Nguyen, D.T., Piras, L., Riegler, M., Zhou, L., Lux, M., and Gurrin, C.: Overview of ImageCLEFlifelog 2018: Daily Living Understanding and Lifelog Moment Retrieval, CLEF2018 Working Notes, Avignon, France, 2018.</p>

<h4 id="task-organizers">Task organizers</h4>
<ul>
  <li>Minh-Son Dao, National Institute of Information and Communications Technology, Japan (NICT) dao (at) nict (dot) go (dot) jp</li>
  <li>Duc-Tien Dang-Nguyen, University of Bergen, Norway (UiB)</li>
  <li>Cathal Gurrin, Dublin City University, Ireland (DCU)</li>
  <li>Thanh Nguyen, University of Information Technology, Vietnam (UIT)</li>
  <li>Tran Minh Triet, University of Science, Vietnam (HCMUS)</li>
</ul>

<h4 id="task-schedule">Task Schedule</h4>
<ul>
  <li>XX XXX: Data release <!-- # Replace XX with your date. We suggest setting the date in June-July--></li>
  <li>XX November: Runs due <!-- # Replace XX with your date. We suggest setting enough time in order to have enough time to assess and return the results by the Results returned deadline--></li>
  <li>XX November: Results returned  <!-- Replace XX with your date. Latest possible should be 15 November--></li>
  <li>22 November: Working notes paper  <!-- Fixed. Please do not change. Exact date to be decided--></li>
  <li>Beginning December: MediaEval 2020 Workshop <!-- Fixed. Please do not change. Exact date to be decided--></li>
</ul>

<!-- #### Acknolwedgments
<!-- # optional, delete if not used-->


      </div>
    </div>

    
<footer class='page-footer green darken-4'>
  <div class='container'>

    <div class='row'>
      <div class="col l6 s12">
        <h5 class="white-text">What is MediaEval?</h5>
        <p>MediaEval is a benchmarking initiative dedicated to evaluating new algorithms for multimedia access and retrieval. 
          It emphasizes the ‘multi’ in multimedia and focuses on human and social aspects of multimedia tasks.</p>

        <p>For more information contact Martha Larson m.larson (at) cs.ru.nl</p>
      </div>
      <div class="col l4 offset-l2 s12">
        <h5 class="white-text">Links</h5>
        <a href='https://twitter.com/multimediaeval' target="_blank">
          <i class="fa fa-twitter fa-3x" aria-hidden="true" style="color:white;"></i>
        </a>
        <a href='https://github.com/multimediaeval' target="_blank">
          <i class="fa fa-github fa-3x" aria-hidden="true" style="color:white;"></i>
        </a>
        <a href='https://www.flickr.com/photos/69524595@N06/' target="_blank">
          <i class="fa fa-flickr fa-3x" aria-hidden="true" style="color:white;"></i>
        </a>
        <a href='https://www.youtube.com/channel/UCc-1NW1Uo2o_zI4F81iyTcw' target="_blank">
          <i class="fa fa-youtube fa-3x" aria-hidden="true" style="color:white;"></i>
        </a>
      </div>
    </div>

  </div>
    <div class="footer-copyright">
      <div class="container grey-text text-lighten-4">
      &copy; 2020 MediaEval Multimedia Benchmark
    </div>
  </div>
</footer>


    <!--JavaScript at end of body for optimized loading-->
    <script type="text/javascript" src="/assets/js/materialize.min.js"></script>
    <script type="text/javascript" src="/assets/js/main.js"></script>
  </body>

</html>
